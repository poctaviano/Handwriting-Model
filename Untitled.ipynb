{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict\n",
      "lstm1_layer.attention.query_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.query_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.key_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.key_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.value_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.value_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.out_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.attention.out_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.linear1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.linear1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.linear2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.linear2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.norm1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.norm1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.norm2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer.norm2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm1_layer2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "window_layer.parameter_layer.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "window_layer.parameter_layer.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.query_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.query_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.key_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.key_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.value_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.value_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.out_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.attention.out_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.linear1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.linear1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.linear2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.linear2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.norm1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.norm1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.norm2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm2_layer.norm2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.query_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.query_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.key_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.key_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.value_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.value_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.out_projection.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.attention.out_projection.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.linear1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.linear1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.linear2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.linear2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.norm1.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.norm1.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.norm2.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "lstm3_layer.norm2.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "output_layer.parameter_layer.weight\n",
      "----------------------------------------------------------------------------------------------------\n",
      "output_layer.parameter_layer.bias\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "optim_dict\n",
      "state\n",
      "----------------------------------------------------------------------------------------------------\n",
      "param_groups\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parameters\n",
      "alphabet_size\n",
      "----------------------------------------------------------------------------------------------------\n",
      "hidden_size\n",
      "----------------------------------------------------------------------------------------------------\n",
      "num_window_components\n",
      "----------------------------------------------------------------------------------------------------\n",
      "num_mixture_components\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('trained_models/trained_model.pt')\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, val in state_dict.items():\n",
    "    print(k)\n",
    "    for v in val:\n",
    "        print(v)\n",
    "        print('-'*100)\n",
    "    print('-'*100)\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from .dataset import IAMDataset\n",
    "from .model import HandwritingGenerator\n",
    "from .loss import HandwritingLoss\n",
    "from copy import deepcopy\n",
    "from .utils import plotstrokes\n",
    "from typing import Union\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, parameters):\n",
    "\n",
    "        self.params = parameters\n",
    "\n",
    "        # Initialize datasets\n",
    "        self.trainset = IAMDataset(self.params)\n",
    "\n",
    "        self.alphabet = self.trainset.alphabet\n",
    "        alphabet_size = len(self.alphabet)\n",
    "\n",
    "        # Initialize loaders\n",
    "        self.trainloader = DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=self.params.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.params.num_workers,\n",
    "            sampler=RandomSampler(self.trainset),\n",
    "        )\n",
    "\n",
    "        # Checking for GPU\n",
    "        self.use_gpu = self.params.use_gpu and torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda:0\" if self.use_gpu else \"cpu\")\n",
    "\n",
    "        try:\n",
    "            path = self.params.model_dir / f\"trained_model_{self.params.idx}.pt\"\n",
    "            print(f\"Loading model : {path}\")\n",
    "            self.model = self.load_model(path)\n",
    "            print(f\"'{path}' model loaded!\")\n",
    "        except Exception as e:\n",
    "            print(f\"{path} model not found.\")\n",
    "            print(\"Creating new model.\")\n",
    "            self.model = HandwritingGenerator(\n",
    "                alphabet_size=alphabet_size,\n",
    "                hidden_size=self.params.hidden_size,\n",
    "                num_window_components=self.params.num_window_components,\n",
    "                num_mixture_components=self.params.num_mixture_components,\n",
    "            )\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        print(self.model)\n",
    "\n",
    "        print(\"Number of parameters = {}\".format(self.model.num_parameters()))\n",
    "\n",
    "        # Optimizer setup\n",
    "        self.optimizer = self.optimizer_select()\n",
    "\n",
    "        # Criterion\n",
    "        self.criterion = HandwritingLoss(self.params)\n",
    "\n",
    "    def train_model(self):\n",
    "        min_loss = None\n",
    "        best_model = self.model.state_dict()\n",
    "        avg_losses = np.zeros(self.params.num_epochs)\n",
    "        self.params.model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        path = self.params.model_dir / f\"trained_model_{self.params.idx}.pt\"\n",
    "        for epoch in range(self.params.num_epochs):\n",
    "            try:\n",
    "                print(\"Epoch {}\".format(epoch + 1))\n",
    "\n",
    "                # Set mode to training\n",
    "                self.model.train()\n",
    "\n",
    "                # Go through the training set\n",
    "                avg_losses[epoch] = self.train_epoch()\n",
    "\n",
    "                print(\"Average loss = {:.3f}\".format(avg_losses[epoch]))\n",
    "\n",
    "                if min_loss is None or min_loss >= avg_losses[epoch]:\n",
    "                    min_loss = avg_losses[epoch]\n",
    "                    best_model = self.model.state_dict()\n",
    "\n",
    "                if (epoch + 1) % 5 == 0:\n",
    "                    self.save_model(best_model, path)\n",
    "\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"Training was interrupted\")\n",
    "                break\n",
    "        # Saving trained model\n",
    "        print(\"Saving model...\")\n",
    "        self.save_model(best_model, path)\n",
    "        return avg_losses\n",
    "\n",
    "    def train_epoch(self):\n",
    "        losses = 0.0\n",
    "        inf = float(\"inf\")\n",
    "        for batch_index, (data) in enumerate(self.trainloader, 1):\n",
    "            if batch_index % 20 == 0:\n",
    "                print(\"Step {}\".format(batch_index))\n",
    "                print(\"Average Loss so far: {}\".format(losses / batch_index))\n",
    "            # Split data tuple\n",
    "            onehot, strokes = data\n",
    "            # Plot strokes\n",
    "            # plotstrokes(strokes)\n",
    "            # Move inputs to correct device\n",
    "            onehot, strokes = onehot.to(self.device), strokes.to(self.device)\n",
    "            # Main Model Forward Step\n",
    "            self.model.reset_state()\n",
    "            loss = None\n",
    "            for idx in range(strokes.size(1) - 1):\n",
    "                output, _ = self.model(strokes[:, idx : idx + 1, :], onehot)\n",
    "                # Loss Computation\n",
    "                loss = (\n",
    "                    self.criterion(output, strokes[:, idx + 1 : idx + 2, :])\n",
    "                    / strokes.size(1)\n",
    "                    if loss is None\n",
    "                    else loss\n",
    "                    + self.criterion(output, strokes[:, idx + 1 : idx + 2, :])\n",
    "                    / strokes.size(1)\n",
    "                )\n",
    "            if loss.data.item() == inf or loss.data.item() == -inf:\n",
    "                print(\"Warning, received inf loss. Skipping it\")\n",
    "            elif loss.data.item() != loss.data.item():\n",
    "                print(\"Warning, received NaN loss.\")\n",
    "            else:\n",
    "                losses = losses + loss.data.item()\n",
    "            # Zero the optimizer gradient\n",
    "            self.optimizer.zero_grad()\n",
    "            # Backward step\n",
    "            loss.backward()\n",
    "            # Clip gradients\n",
    "            clip_grad_norm_(self.model.parameters(), self.params.max_norm)\n",
    "            # Weight Update\n",
    "            self.optimizer.step()\n",
    "            if self.use_gpu is True:\n",
    "                torch.cuda.synchronize()\n",
    "            del onehot, strokes, data\n",
    "        # Compute the average loss for this epoch\n",
    "        avg_loss = losses / len(self.trainloader)\n",
    "        return avg_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Union[Path, str]):\n",
    "        package = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        parameters = package[\"parameters\"]\n",
    "        state_dict = package[\"state_dict\"]\n",
    "        return HandwritingGenerator.load_model(parameters, state_dict)\n",
    "\n",
    "    def save_model(self, model_parameters, path):\n",
    "        model = deepcopy(self.model)\n",
    "        model.load_state_dict(model_parameters)\n",
    "        torch.save(\n",
    "            self.serialize(model), path,\n",
    "        )\n",
    "\n",
    "    def serialize(self, model):\n",
    "        model_is_cuda = next(model.parameters()).is_cuda\n",
    "        model = model.cpu() if model_is_cuda else self.model\n",
    "        package = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optim_dict\": self.optimizer.state_dict(),\n",
    "            \"parameters\": {\n",
    "                \"alphabet_size\": self.model.alphabet_size,\n",
    "                \"hidden_size\": self.model.hidden_size,\n",
    "                \"num_window_components\": self.model.num_window_components,\n",
    "                \"num_mixture_components\": self.model.num_mixture_components,\n",
    "            },\n",
    "        }\n",
    "        return package\n",
    "\n",
    "    def optimizer_select(self):\n",
    "        if self.params.optimizer == \"Adam\":\n",
    "            return optim.Adam(self.model.parameters(), lr=self.params.learning_rate)\n",
    "        elif self.params.optimizer == \"Adadelta\":\n",
    "            return optim.Adadelta(self.model.parameters(), lr=self.params.learning_rate)\n",
    "        elif self.params.optimizer == \"SGD\":\n",
    "            return optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.params.learning_rate,\n",
    "                momentum=self.params.momentum,\n",
    "                nesterov=self.params.nesterov,\n",
    "            )\n",
    "        elif self.params.optimizer == \"RMSprop\":\n",
    "            return optim.RMSprop(\n",
    "                self.model.parameters(),\n",
    "                lr=self.params.learning_rate,\n",
    "                momentum=self.params.momentum,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> \u001b[0;32m/home/iorua8/.local/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m(252)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    250 \u001b[0;31m        \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    251 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 252 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    253 \u001b[0;31m        \"\"\"Printing with history cache management.\n",
      "\u001b[0m\u001b[0;32m    254 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> f\n",
      "*** NameError: name 'f' is not defined\n",
      "ipdb> \n",
      "*** NameError: name 'f' is not defined\n",
      "ipdb> d\n",
      "*** Newest frame\n",
      "ipdb> d\n",
      "*** Newest frame\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
